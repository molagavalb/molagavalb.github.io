<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interpretable Modelling of Emotional Intelligence in AI</title>
    <meta name="description" content="An independent analytical exploration of modelling emotional intelligence from text using interpretable machine learning techniques.">
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif;
            line-height: 1.7;
            color: #222;
            max-width: 820px;
            margin: 40px auto;
            padding: 0 20px;
            background-color: #ffffff;
        }
        h1, h2, h3 {
            color: #111;
            line-height: 1.3;
        }
        h1 {
            font-size: 2.2em;
            margin-bottom: 10px;
        }
        h2 {
            margin-top: 40px;
        }
        p {
            margin: 18px 0;
        }
        .meta {
            color: #555;
            font-size: 0.95em;
            margin-bottom: 30px;
        }
        a {
            color: #0a66c2;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        .note {
            background: #f6f8fa;
            padding: 16px;
            border-left: 4px solid #0a66c2;
            margin: 30px 0;
        }
        footer {
            margin-top: 60px;
            font-size: 0.9em;
            color: #555;
        }
    </style>
</head>

<body>

<h1>Interpretable Modelling of Emotional Intelligence in AI</h1>

<div class="meta">
    <strong>Author:</strong> [Bhaskar Molagavalli]<br>
    <strong>Date:</strong> [October 2025]<br>
    <strong>Project Repository:</strong>
    <a href="https://github.com/molagavalb/Predictive-Model-for-Emotional-Intelligence" target="_blank">
        GitHub – Predictive Model for Emotional Intelligence
    </a>
</div>

<p>
This page documents an independent analytical project exploring whether emotional intelligence (EI)
can be inferred from text-based behavioural data using interpretable machine learning techniques.
The focus of this work is not automation or deployment, but understanding how textual signals interact
with simple classification models and what those interactions reveal about the limits of emotional
modelling in AI systems.
</p>

<h2>Problem Context</h2>

<p>
Emotional intelligence is inherently difficult to model because it is not directly observable.
Unlike structured variables, EI is expressed implicitly through language, behaviour, and context,
and varies significantly across individuals and situations.
</p>

<p>
This project approaches emotional intelligence as a probabilistic inference problem rather than
a definitive measurement, acknowledging uncertainty and ambiguity as core characteristics of the domain.
</p>

<h2>Why Text-Based Modelling Is Challenging</h2>

<p>
Text data introduces high dimensionality, contextual ambiguity, and sensitivity to linguistic variation.
Small changes in wording or tone can substantially alter meaning, making robust emotional inference
particularly challenging.
</p>

<p>
Because of these characteristics, this work prioritises transparency and interpretability over
maximum predictive performance.
</p>

<h2>Design Decisions</h2>

<h3>Model Choice</h3>

<p>
Logistic Regression was selected intentionally due to its interpretability. The ability to inspect
feature coefficients and reason about model behaviour was considered essential when working with
emotionally sensitive data.
</p>

<h3>Feature Representation</h3>

<p>
IDF-based vectorisation was used instead of contextual embeddings to preserve visibility into
feature influence. While embeddings offer richer semantic representation, they often obscure
individual feature contributions and complicate diagnostic analysis.
</p>

<p>
This trade-off reflects a broader principle in behavioural modelling: interpretability can be
more valuable than raw predictive power when the goal is understanding rather than automation.
</p>

<h2>Insights and Observations</h2>

<p>
The model demonstrated that simple lexical features can capture certain behavioural patterns,
but also revealed clear limitations in handling nuanced or context-dependent emotional expression.
</p>

<p>
Failure modes included sensitivity to domain-specific language, indirect emotional cues, and
surface-level lexical correlations. These behaviours highlight the risks of over-interpreting
model outputs in emotionally complex domains.
</p>

<h2>Bias and Ethical Considerations</h2>

<p>
Potential sources of bias include linguistic and cultural variation in emotional expression,
dataset imbalance, and overrepresentation of dominant language patterns. These factors were
considered throughout evaluation and interpretation.
</p>

<p>
This work does not advocate for automated emotional assessment. Any applied use of similar
approaches should involve human oversight and clear limitations on interpretation.
</p>

<h2>Limitations and Future Directions</h2>

<p>
This approach is not suitable for high-stakes decision-making or individual psychological assessment.
It should be treated strictly as an analytical exploration rather than a deployable system.
</p>

<p>
Future work could explore comparative evaluation with contextual embeddings, multi-modal behavioural
signals, and bias-aware evaluation frameworks, while maintaining transparency and interpretability.
</p>
    <h2>Feature Engineering</h2>
<img src="images/screenshot2-3.png"
     alt="TF-IDF feature representation used in the model"
     style="max-width:100%; border:1px solid #ddd; margin:20px 0;">

<h2>Model Evaluation</h2>
<img src="images/screenshot3-4.png"
     alt="Model evaluation and diagnostic output"
     style="max-width:100%; border:1px solid #ddd; margin:20px 0;">
<img src="images/screenshot4-5.png"
     alt="Model evaluation and diagnostic output"
     style="max-width:100%; border:1px solid #ddd; margin:20px 0;">


<div class="note">
    <strong>Author’s Note:</strong><br>
    This project was developed independently from start to finish, including problem formulation,
    feature engineering, model development, evaluation, and analysis. It is shared publicly to
    contribute to broader discussion on interpretable and responsible AI in emotionally sensitive domains.
</div>

<footer>
    © [2025] [Bhaskar Molagavalli] · Independent Research & Analysis
</footer>

</body>
</html>
